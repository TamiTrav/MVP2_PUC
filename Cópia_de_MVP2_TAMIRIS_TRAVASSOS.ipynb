{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoIb7deQSGu5QxMAnsT3UY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TamiTrav/MVP2_PUC/blob/main/C%C3%B3pia_de_MVP2_TAMIRIS_TRAVASSOS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MVP de Machine Learning e Deep Learning\n"
      ],
      "metadata": {
        "id": "pvD0ejA78HIq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Profs. Hugo Villamizar e Patrick Happ"
      ],
      "metadata": {
        "id": "nQpxAbimQ6Ub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Aluna: Tamiris Severino Travassos**"
      ],
      "metadata": {
        "id": "gvPHg0MBRCpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PARTE 1 - MACHINE LEARNING"
      ],
      "metadata": {
        "id": "HbNsyvgKRZjK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.Definição do problema"
      ],
      "metadata": {
        "id": "4PJ4CgazRmTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objetivo: entender e descrever claramente o problema que está sendo resolvido.**"
      ],
      "metadata": {
        "id": "53zrYVA0cHw6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qual é a descrição do problema?  \n",
        "\n",
        "\n",
        "*   Clientes de uma instituição financeira, que serão testados através de companhas de marketing  \n",
        "*   Identificar e segmentar a clientela em diferentes perfis. Ajudando na escolha do público-alvo de futuras campanhas.\n",
        "\n",
        "\n",
        "\n",
        "Você tem premissas ou hipóteses sobre o problema? Quais?\n",
        "      \n",
        "      \n",
        "\n",
        "Que restrições ou condições foram impostas para selecionar os dados?\n",
        "\n",
        "Descreva o seu dataset (atributos, imagens, anotações, etc)."
      ],
      "metadata": {
        "id": "pSVq76r0Ytev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1.Informações sobre os atributos"
      ],
      "metadata": {
        "id": "23_SaJ6MR6lK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Idade (numérica) \n",
        "\n",
        "2. Profissão: (categorial): 'admin.','colarinho azul','empresário',\n",
        "'empregada doméstica','administração','aposentado' ,'autônomo','serviços','estudante','técnico','desempregado','desconhecido'\n",
        "\n",
        "3. Estado civil (categorial: 'divorciado','casado','solteiro','desconhecido '; nota: 'divorciado' significa divorciado ou viúvo) \n",
        "\n",
        "4. Escolaridade (categorial: 'básico.4a','básico.6a','básico.9a','ensino médio','analfabeto','curso.profissional ','university.degree','unknown') \n",
        "\n",
        "5. Default - Tem crédito em default? (categorial: 'não','sim','desconhecido') \n",
        "\n",
        "6. Habitação - Tem crédito habitação? (categorial: 'não','sim','desconhecido') \n",
        "\n",
        "7. Empréstimo - Tem empréstimo pessoal? (categorial: 'não','sim','desconhecido') -  referente ao último contato da campanha atual.\n",
        "\n",
        "8. Contato- Tipo de comunicação do contato (categorial: 'celular','telefone') \n",
        "\n",
        "9. Mes Contato - Último contato mês do ano (categorial: 'jan', 'fev', 'mar', ..., 'nov', 'dez') \n",
        "\n",
        "10. Dia contato : último dia de contato (numérica) \n",
        "\n",
        "11. Número de contatos realizados durante esta campanha e para este cliente (numérico, inclui último contato) \n",
        "\n",
        "12. Número de dias que se passaram desde o último contato com o cliente de uma campanha anterior (numérico; 999 significa que o cliente não foi contactado anteriormente) \n",
        "\n",
        "13. Número de contactos realizados antes desta campanha e para este cliente (numérico) \n",
        "\n",
        "14. Resultado da campanha de marketing anterior (categorial: 'fracasso', 'inexistente', 'sucesso') # atributos de contexto social e econômico \n",
        "\n",
        "15. Emp.var.rate: taxa de variação do emprego - indicador trimestral (numérico) \n",
        "\n",
        "16. Cons.price.idx: índice de preços no consumidor - indicador mensal (numérico) \n",
        "\n",
        "17. Cons.conf.idx: índice de confiança do consumidor - indicador mensal (numérico) \n",
        "\n",
        "18. Euribor3m: euribor 3 meses taxa - indicador diário (numérico) \n",
        "\n",
        "19. N.º de empregados: número de trabalhadores - indicador trimestral (numérico) Variável de saída (meta pretendida): 21 - y - o cliente subscreveu depósito a prazo? (binário: 'sim', 'não')\n",
        "\n"
      ],
      "metadata": {
        "id": "_FUjWlflYjZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# configuração para não exibir os warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Imports necessários\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "F4FR2u_-SOKY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.Carga de dados"
      ],
      "metadata": {
        "id": "cvcxba2aSTfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carrega arquivo csv usando Pandas, o banco de dados está no github\n",
        "# Informa a URL de importação dos datasets"
      ],
      "metadata": {
        "id": "pTIQ9eL-SaXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lê o arquivo\n",
        "banco_original = pd.read_csv('https://raw.githubusercontent.com/TamiTrav/MVP2_PUC/main/base.csv', sep=';')\n",
        "\n",
        "# Mostra as primeiras linhas do dataset\n",
        "banco_original.head()"
      ],
      "metadata": {
        "id": "EaH-_bleShKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.Preparação dos dados"
      ],
      "metadata": {
        "id": "5kpcFzH2VtVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objetivo: realizar operações de preparação dos dados.**"
      ],
      "metadata": {
        "id": "zDf8APkicCVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1.Separação em conjunto de treino e conjunto de teste com holdout"
      ],
      "metadata": {
        "id": "Yol5fGxbY_9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separe o dataset entre treino e teste (e validação, se aplicável).\n",
        "\n",
        "Faz sentido utilizar um método de validação cruzada? Justifique se não utilizar.\n",
        "\n",
        "\n",
        "Verifique quais operações de transformação de dados (como normalização e padronização, transformação de imagens em tensores) são mais apropriadas para o seu problema e salve visões diferentes do seu dataset para posterior avaliação dos modelos.\n",
        "\n",
        "Refine a quantidade de atributos disponíveis, realizando o processo de feature selection de forma adequada."
      ],
      "metadata": {
        "id": "wRGXk7MoZm8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_size = 0.20 # tamanho do conjunto de teste\n",
        "seed = 7 # semente aleatória\n",
        "\n",
        "\n",
        "# Separação em conjuntos de treino e teste\n",
        "array = banco_original.values\n",
        "X = array[:,0:20]\n",
        "y = array[:,20]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "    test_size=test_size, shuffle=True, random_state=seed, stratify=y) # holdout com estratificação\n",
        "\n",
        "\n",
        "# Parâmetros e partições da validação cruzada\n",
        "scoring = 'accuracy'\n",
        "num_particoes = 10\n",
        "kfold = StratifiedKFold(n_splits=num_particoes, shuffle=True, random_state=seed) # validação cruzada com estratificação"
      ],
      "metadata": {
        "id": "C-gOYl4eWj57"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2.Criação e avaliação de modelos: linha base"
      ],
      "metadata": {
        "id": "zELXlLUdXhkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(7) # definindo uma semente global\n",
        "\n",
        "# Lista que armazenará os modelos\n",
        "models = []\n",
        "\n",
        "# Criando os modelos e adicionando-os na lista de modelos\n",
        "models.append(('LR', LogisticRegression(max_iter=200))) \n",
        "models.append(('KNN', KNeighborsClassifier())) \n",
        "models.append(('CART', DecisionTreeClassifier())) \n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC()))\n",
        "\n",
        "# Definindo os parâmetros do classificador base para o BaggingClassifier\n",
        "base = DecisionTreeClassifier()\n",
        "num_trees = 100\n",
        "max_features = 3\n",
        "\n",
        "# Criando os modelos para o VotingClassifier\n",
        "bases = []\n",
        "model1 = LogisticRegression(max_iter=200)\n",
        "bases.append(('logistic', model1))\n",
        "model2 = DecisionTreeClassifier()\n",
        "bases.append(('cart', model2))\n",
        "model3 = SVC()\n",
        "bases.append(('svm', model3))\n",
        "\n",
        "# Criando os ensembles e adicionando-os na lista de modelos\n",
        "models.append(('Bagging', BaggingClassifier(base_estimator=base, n_estimators=num_trees)))\n",
        "models.append(('RF', RandomForestClassifier(n_estimators=num_trees, max_features=max_features)))\n",
        "models.append(('ET', ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)))\n",
        "models.append(('Ada', AdaBoostClassifier(n_estimators=num_trees)))\n",
        "models.append(('GB', GradientBoostingClassifier(n_estimators=num_trees)))\n",
        "models.append(('Voting', VotingClassifier(bases)))\n",
        "\n",
        "# Listas para armazenar os resultados\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "# Avaliação dos modelos\n",
        "for name, model in models:\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n",
        "\n",
        "# Boxplot de comparação dos modelos\n",
        "fig = plt.figure(figsize=(15,10)) \n",
        "fig.suptitle('Comparação dos Modelos') \n",
        "ax = fig.add_subplot(111) \n",
        "plt.boxplot(results) \n",
        "ax.set_xticklabels(names) \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mKKWfSoMWmoz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.3.Criação e avaliação de modelos: dados padronizados e normalizados"
      ],
      "metadata": {
        "id": "o7p54qasZYbU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verifique quais operações de transformação de dados (como normalização e padronização, transformação de imagens em tensores) são mais apropriadas para o seu problema e salve visões diferentes do seu dataset para posterior avaliação dos modelos."
      ],
      "metadata": {
        "id": "jZ6zUW6CZXLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(7) # definindo uma semente global para este bloco\n",
        "\n",
        "# Listas para armazenar os armazenar os pipelines e os resultados para todas as visões do dataset\n",
        "pipelines = []\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "\n",
        "# Criando os elementos do pipeline\n",
        "\n",
        "# Algoritmos que serão utilizados\n",
        "reg_log = ('LR', LogisticRegression(max_iter=200))\n",
        "knn = ('KNN', KNeighborsClassifier())\n",
        "cart = ('CART', DecisionTreeClassifier())\n",
        "naive_bayes = ('NB', GaussianNB())\n",
        "svm = ('SVM', SVC())\n",
        "bagging = ('Bag', BaggingClassifier(base_estimator=base, n_estimators=num_trees))\n",
        "random_forest = ('RF', RandomForestClassifier(n_estimators=num_trees, max_features=max_features))\n",
        "extra_trees = ('ET', ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features))\n",
        "adaboost = ('Ada', AdaBoostClassifier(n_estimators=num_trees))\n",
        "gradient_boosting = ('GB', GradientBoostingClassifier(n_estimators=num_trees))\n",
        "voting = ('Voting', VotingClassifier(bases))\n",
        "\n",
        "# Transformações que serão utilizadas\n",
        "standard_scaler = ('StandardScaler', StandardScaler())\n",
        "min_max_scaler = ('MinMaxScaler', MinMaxScaler())\n",
        "\n",
        "# Montando os pipelines\n",
        "\n",
        "# Dataset original\n",
        "pipelines.append(('LR-orig', Pipeline([reg_log]))) \n",
        "pipelines.append(('KNN-orig', Pipeline([knn])))\n",
        "pipelines.append(('CART-orig', Pipeline([cart])))\n",
        "pipelines.append(('NB-orig', Pipeline([naive_bayes])))\n",
        "pipelines.append(('SVM-orig', Pipeline([svm])))\n",
        "pipelines.append(('Bag-orig', Pipeline([bagging])))\n",
        "pipelines.append(('RF-orig', Pipeline([random_forest])))\n",
        "pipelines.append(('ET-orig', Pipeline([extra_trees])))\n",
        "pipelines.append(('Ada-orig', Pipeline([adaboost])))\n",
        "pipelines.append(('GB-orig', Pipeline([gradient_boosting])))\n",
        "pipelines.append(('Vot-orig', Pipeline([voting])))\n",
        "\n",
        "# Dataset Padronizado\n",
        "pipelines.append(('LR-padr', Pipeline([standard_scaler, reg_log]))) \n",
        "pipelines.append(('KNN-padr', Pipeline([standard_scaler, knn])))\n",
        "pipelines.append(('CART-padr', Pipeline([standard_scaler, cart])))\n",
        "pipelines.append(('NB-padr', Pipeline([standard_scaler, naive_bayes])))\n",
        "pipelines.append(('SVM-padr', Pipeline([standard_scaler, svm])))\n",
        "pipelines.append(('Bag-padr', Pipeline([standard_scaler, bagging]))) \n",
        "pipelines.append(('RF-padr', Pipeline([standard_scaler, random_forest])))\n",
        "pipelines.append(('ET-padr', Pipeline([standard_scaler, extra_trees])))\n",
        "pipelines.append(('Ada-padr', Pipeline([standard_scaler, adaboost])))\n",
        "pipelines.append(('GB-padr', Pipeline([standard_scaler, gradient_boosting])))\n",
        "pipelines.append(('Vot-padr', Pipeline([standard_scaler, voting])))\n",
        "\n",
        "# Dataset Normalizado\n",
        "pipelines.append(('LR-norm', Pipeline([min_max_scaler, reg_log]))) \n",
        "pipelines.append(('KNN-norm', Pipeline([min_max_scaler, knn])))\n",
        "pipelines.append(('CART-norm', Pipeline([min_max_scaler, cart])))\n",
        "pipelines.append(('NB-norm', Pipeline([min_max_scaler, naive_bayes])))\n",
        "pipelines.append(('SVM-norm', Pipeline([min_max_scaler, svm])))\n",
        "pipelines.append(('Bag-norm', Pipeline([min_max_scaler, bagging]))) \n",
        "pipelines.append(('RF-norm', Pipeline([min_max_scaler, random_forest])))\n",
        "pipelines.append(('ET-norm', Pipeline([min_max_scaler, extra_trees])))\n",
        "pipelines.append(('Ada-norm', Pipeline([min_max_scaler, adaboost])))\n",
        "pipelines.append(('GB-norm', Pipeline([min_max_scaler, gradient_boosting])))\n",
        "pipelines.append(('Vot-norm', Pipeline([min_max_scaler, voting])))\n",
        "\n",
        "# Executando os pipelines\n",
        "for name, model in pipelines:\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %.3f (%.3f)\" % (name, cv_results.mean(), cv_results.std()) # formatando para 3 casas decimais\n",
        "    print(msg)\n",
        "\n",
        "# Boxplot de comparação dos modelos\n",
        "fig = plt.figure(figsize=(25,6))\n",
        "fig.suptitle('Comparação dos Modelos - Dataset orginal, padronizado e normalizado') \n",
        "ax = fig.add_subplot(111) \n",
        "plt.boxplot(results) \n",
        "ax.set_xticklabels(names, rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mni6WsrVbTGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.Modelagem e Treinamento"
      ],
      "metadata": {
        "id": "YnUpGnx5XYgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objetivo: construir modelos para resolver o problema em questão.**"
      ],
      "metadata": {
        "id": "0PnXp3rkb6s6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecione os algoritmos mais indicados para o problema e dataset escolhidos, justificando as suas escolhas.\n",
        "Há algum ajuste inicial para os hiperparâmetros?\n",
        "O modelo foi devidamente treinado? Foi observado problema de underfitting?\n",
        "É possível otimizar os hiperparâmetros de algum dos modelos? Se sim, faça-o, justificando todas as escolhas.\n",
        "Há algum método avançado ou mais complexo que possa ser avaliado?\n",
        "Posso criar um comitê de modelos diferentes para o problema (ensembles)?"
      ],
      "metadata": {
        "id": "GP-j2Dy0b4I2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.2.Otimização dos hiperparâmetros"
      ],
      "metadata": {
        "id": "BeEgsGjUcPnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuning do KNN\n",
        "\n",
        "np.random.seed(7) # definindo uma semente global para este bloco\n",
        "\n",
        "pipelines = []\n",
        "\n",
        "# Definindo os componentes do pipeline\n",
        "knn = ('KNN', KNeighborsClassifier())\n",
        "standard_scaler = ('StandardScaler', StandardScaler())\n",
        "min_max_scaler = ('MinMaxScaler', MinMaxScaler())\n",
        "\n",
        "pipelines.append(('knn-orig', Pipeline(steps=[knn])))\n",
        "pipelines.append(('knn-padr', Pipeline(steps=[standard_scaler, knn])))\n",
        "pipelines.append(('knn-norm', Pipeline(steps=[min_max_scaler, knn])))\n",
        "\n",
        "param_grid = {\n",
        "    'KNN__n_neighbors': [1,3,5,7,9,11,13,15,17,19,21],\n",
        "    'KNN__metric': [\"euclidean\", \"manhattan\", \"minkowski\"],\n",
        "}\n",
        "\n",
        "# Prepara e executa o GridSearchCV\n",
        "for name, model in pipelines:    \n",
        "    grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
        "    grid.fit(X_train, y_train)\n",
        "    # imprime a melhor configuração\n",
        "    print(\"Sem tratamento de missings: %s - Melhor: %f usando %s\" % (name, grid.best_score_, grid.best_params_)) "
      ],
      "metadata": {
        "id": "ntRykNLmbkOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.3.Finalização do Modelo"
      ],
      "metadata": {
        "id": "0nCxwMTTcX7n"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y1O6Ku6mcZ2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.Avaliação dos resultados"
      ],
      "metadata": {
        "id": "JZU76CUhcwPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objetivo: analisar o desempenho dos modelos gerados em dados não vistos (com a base de teste)**"
      ],
      "metadata": {
        "id": "rRU1UuTUc_Mh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecione as métricas de avaliação condizentes com o problema, justificando.\n",
        "\n",
        "Treine o modelo escolhido com toda a base de treino, e teste-o com a base de teste.\n",
        "\n",
        "Os resultados fazem sentido?\n",
        "\n",
        "Foi observado algum problema de overfitting?\n",
        "\n",
        "Compare os resultados de diferentes modelos.\n",
        "\n",
        "Descreva a melhor solução encontrada, justificando."
      ],
      "metadata": {
        "id": "I60vf4ZVc8jx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1sbN08oadENI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PARTE 2 - DEEP LEARNING"
      ],
      "metadata": {
        "id": "7V041qkLReCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1.Definição do problema**"
      ],
      "metadata": {
        "id": "ai6pgaMwRMuU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuMnMwUs7hno"
      },
      "outputs": [],
      "source": []
    }
  ]
}